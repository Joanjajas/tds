{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from collections import namedtuple\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "TARGET_DIR = \"segmented_digits/\"\n",
    "AUDIO_DIR = \"audios/\"  # each person audios should be stored inside its own directory\n",
    "METHOD = \"mid_values\"  # \"start_end\" or \"mid_values\"\n",
    "\n",
    "START_END_SPAN = 0.35  # seconds to add before and after the start and end of the digit\n",
    "MID_VALUES_SPAN = 0.5  # seconds to add before and after the mid value of the digit\n",
    "SPEECH_THRESHOLD = 0.05  # energy threshold to consider a frame as speech\n",
    "DISPERSION = 0.5  # minimum separation in seconds between two energy peaks to be considered different digits\n",
    "\n",
    "\n",
    "if METHOD not in [\"start_end\", \"mid_values\"]:\n",
    "    raise ValueError(\"Invalid method\")\n",
    "\n",
    "Signal = namedtuple(\"Signal\", [\"y\", \"fs\", \"file\"])\n",
    "\n",
    "\n",
    "def signal_from_file(filename):\n",
    "    fs, y = wav.read(filename)\n",
    "\n",
    "    if np.any(abs(y) > 1):\n",
    "        if np.issubdtype(y.dtype, np.integer):\n",
    "            y = y / np.iinfo(y.dtype).max\n",
    "        elif np.issubdtype(y.dtype, np.floating):\n",
    "            y = y / np.finfo(y.dtype).max\n",
    "        else:\n",
    "            raise ValueError(\"No quiero quedarme sordo\")\n",
    "\n",
    "    return Signal(y, fs, os.path.basename(filename))\n",
    "\n",
    "\n",
    "def plot_signal(y, fs, title, peaks=None, hlines=None, vlines=None):\n",
    "    t = np.arange(len(y)) / fs\n",
    "    plt.plot(t, y)\n",
    "\n",
    "    if peaks is not None:\n",
    "        plt.plot(peaks / fs, y[peaks], \"x\")\n",
    "\n",
    "    if hlines is not None:\n",
    "        for y in hlines:\n",
    "            plt.axhline(y, color=\"r\", linestyle=\"--\")\n",
    "\n",
    "    if vlines is not None:\n",
    "        for x in vlines:\n",
    "            plt.axvline(x, color=\"r\", linestyle=\"--\")\n",
    "\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def non_overlapping_frames(signal, frame_duration):\n",
    "    frame_len = round(frame_duration * signal.fs)\n",
    "    total_frames = len(signal.y) // frame_len\n",
    "\n",
    "    frames = signal.y[: total_frames * frame_len]\n",
    "    frames = frames.reshape(frame_len, total_frames, order=\"F\")\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def speech_segments(signal, energy_threshold, dispersion, method=\"mid_values\"):\n",
    "    # plot_signal(signal.y, signal.fs, title=f\"{signal.file}\")\n",
    "\n",
    "    frame_duration = 0.02\n",
    "    frames_fs = 1 / frame_duration\n",
    "    frames = non_overlapping_frames(signal, frame_duration)\n",
    "\n",
    "    energy_frames = np.sum(frames**2, axis=0)\n",
    "    energy_peaks, _ = find_peaks(\n",
    "        energy_frames, height=energy_threshold * np.max(energy_frames)\n",
    "    )\n",
    "\n",
    "    last_peak = energy_peaks[0]\n",
    "    current_peaks = []\n",
    "    energy_mid_values = []\n",
    "    digit_start_end = []\n",
    "    for peak in energy_peaks:\n",
    "        if peak - last_peak < dispersion * frames_fs:\n",
    "            current_peaks.append(peak)\n",
    "        else:\n",
    "            energy_mid_values.append(np.mean(current_peaks))\n",
    "            digit_start_end.append((current_peaks[0], current_peaks[-1]))\n",
    "            current_peaks = [peak]\n",
    "\n",
    "        last_peak = peak\n",
    "\n",
    "    energy_mid_values.append(np.mean(current_peaks))\n",
    "    digit_start_end.append((current_peaks[0], current_peaks[-1]))\n",
    "\n",
    "    energy_mid_values = np.array(energy_mid_values)\n",
    "    signal_mid_values = np.array(energy_mid_values) / frames_fs\n",
    "    digit_start_end = np.array(digit_start_end) / frames_fs\n",
    "\n",
    "    # plot_signal(\n",
    "    # energy_frames,\n",
    "    # frames_fs,\n",
    "    # title=f\"Energy {signal.file} peaks\",\n",
    "    # hlines=[energy_threshold * np.max(energy_frames)],\n",
    "    # peaks=energy_peaks,\n",
    "    # )\n",
    "\n",
    "    # if method == \"mid_values\":\n",
    "    #     plot_signal(\n",
    "    #         energy_frames,\n",
    "    #         frames_fs,\n",
    "    #         title=f\"Energy {signal.file} mid values\",\n",
    "    #         peaks=energy_mid_values.astype(int),\n",
    "    #     )\n",
    "\n",
    "    #     plot_signal(\n",
    "    #         signal.y,\n",
    "    #         signal.fs,\n",
    "    #         title=f\"{signal.file} mid values\",\n",
    "    #         vlines=signal_mid_values,\n",
    "    #     )\n",
    "\n",
    "    if method == \"mid_values\":\n",
    "        vlines = np.array(\n",
    "            [\n",
    "                (\n",
    "                    value - MID_VALUES_SPAN,\n",
    "                    value + MID_VALUES_SPAN,\n",
    "                )\n",
    "                for value in signal_mid_values\n",
    "            ]\n",
    "        )\n",
    "    elif method == \"start_end\":\n",
    "        vlines = np.array(\n",
    "            [\n",
    "                ((start - START_END_SPAN, end + START_END_SPAN))\n",
    "                for start, end in digit_start_end\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    plot_signal(\n",
    "        signal.y,\n",
    "        signal.fs,\n",
    "        title=f\"{signal.file} speech segments\",\n",
    "        vlines=vlines.flatten(),\n",
    "    )\n",
    "\n",
    "    empty_signal_duration = 0.5\n",
    "    empty_signal_len = round(empty_signal_duration * signal.fs)\n",
    "    empty_signal = np.zeros(empty_signal_len)\n",
    "\n",
    "    speech_segments = []\n",
    "\n",
    "    if method == \"mid_values\":\n",
    "        for i, value in enumerate(signal_mid_values):\n",
    "            digit_start = round((value - MID_VALUES_SPAN) * signal.fs)\n",
    "            digit_end = round((value + MID_VALUES_SPAN) * signal.fs)\n",
    "            digit = np.concatenate(\n",
    "                [empty_signal, signal.y[digit_start:digit_end], empty_signal]\n",
    "            )\n",
    "\n",
    "            # plot_signal(digit, signal.fs, title=f\"{signal.file} number {i}\")\n",
    "            speech_segments.append(digit)\n",
    "\n",
    "    elif method == \"start_end\":\n",
    "        for i, (start, end) in enumerate(digit_start_end):\n",
    "            digit_start = round((start - START_END_SPAN) * signal.fs)\n",
    "            digit_end = round((end + START_END_SPAN) * signal.fs)\n",
    "            digit = np.concatenate(\n",
    "                [empty_signal, signal.y[digit_start:digit_end], empty_signal]\n",
    "            )\n",
    "\n",
    "            # plot_signal(digit, signal.fs, title=f\"{signal.file} number {i}\")\n",
    "            speech_segments.append(digit)\n",
    "\n",
    "    return speech_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_id, directory in enumerate(sorted(os.listdir(AUDIO_DIR))):\n",
    "    dir_path = os.path.join(AUDIO_DIR, directory)\n",
    "\n",
    "    for record_id, file in enumerate(sorted(os.listdir(dir_path))):\n",
    "        digits_name_dict = {\n",
    "            0: \"cero\",\n",
    "            1: \"uno\",\n",
    "            2: \"dos\",\n",
    "            3: \"tres\",\n",
    "            4: \"cuatro\",\n",
    "            5: \"cinco\",\n",
    "            6: \"seis\",\n",
    "            7: \"siete\",\n",
    "            8: \"ocho\",\n",
    "            9: \"nueve\",\n",
    "        }\n",
    "\n",
    "        signal = signal_from_file(os.path.join(dir_path, file))\n",
    "        digits = speech_segments(signal, SPEECH_THRESHOLD, DISPERSION, method=METHOD)\n",
    "\n",
    "        for i, digit in enumerate(digits):\n",
    "            digit_name = digits_name_dict[i]\n",
    "\n",
    "            digit_path = os.path.join(\n",
    "                TARGET_DIR, f\"{digit_name}_{person_id + 1}_{record_id + 1}.wav\"\n",
    "            )\n",
    "\n",
    "            if os.path.exists(digit_path):\n",
    "                os.remove(digit_path)\n",
    "\n",
    "            wav.write(digit_path, signal.fs, (digit * 2**15).astype(np.int16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
