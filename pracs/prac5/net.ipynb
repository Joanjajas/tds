{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "76e5d625-6ba0-44e4-8e7b-b2eaceddf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "19b6020e-c7a7-4a38-bf4f-aad3cde0915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset_train = loadmat(\"training_data.mat\")\n",
    "dataset_validation = loadmat(\"validation_data.mat\")\n",
    "\n",
    "# extract the training and validation data\n",
    "x_train = dataset_train[\"features_train\"]\n",
    "y_train = dataset_train[\"labels_train_int\"].flatten()\n",
    "x_val = dataset_validation[\"features_validation\"]\n",
    "y_val = dataset_validation[\"labels_validation_int\"].flatten()\n",
    "\n",
    "x_train_mean = x_train.mean(axis=0, keepdims=True)\n",
    "x_train_std = x_train.std(axis=0, keepdims=True)\n",
    "\n",
    "x_train_norm = (x_train - x_train_mean) / x_train_std\n",
    "x_val_norm = (x_val - x_train_mean) / x_train_std\n",
    "\n",
    "# Convert lists to tensors\n",
    "x_train_tensor = torch.tensor(x_train_norm, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val_norm, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Create TensorDataset\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "71166b74-d272-4c56-b6f0-e9babaf4976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=85,\n",
    "        hidden_dim=[\n",
    "            4,\n",
    "        ],\n",
    "        activation=nn.ReLU(),\n",
    "        out_dim=10,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        assert len(hidden_dim) > 0, \"at least one hidden layer\"\n",
    "        layers = []\n",
    "\n",
    "        # first layer\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim[0]))\n",
    "        layers.append(nn.BatchNorm1d(hidden_dim[0]))\n",
    "\n",
    "        # dropout\n",
    "        if dropout > 0.0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # activation\n",
    "        layers.append(activation)\n",
    "\n",
    "        # hidden layers\n",
    "        if len(hidden_dim) > 1:\n",
    "            for k in range(1, len(hidden_dim)):\n",
    "                layers.append(nn.Linear(hidden_dim[k - 1], hidden_dim[k]))\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim[k]))\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                layers.append(activation)\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim[-1], out_dim))\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92c88a-e69a-42e2-945f-a98ac6c154ff",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "14707f81-ce61-4243-99a6-6529016a597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(network, loss_fn, dataloader, optimizer, device=\"cpu\"):\n",
    "    # Set the network to train mode\n",
    "    network.to(device)\n",
    "    network.train()\n",
    "\n",
    "    # Initialize variables to keep track of loss and number of batches\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    epoch_correct = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    # Iterate over the data loader\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        # Move data to the appropriate device (e.g., GPU)\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        batch_outputs = network(batch_inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(batch_outputs, batch_targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Calculate the number of correct predictions in the batch\n",
    "        _, predicted = torch.max(batch_outputs, 1)\n",
    "        epoch_correct += (predicted == batch_targets).sum().item()\n",
    "        num_samples += batch_targets.size(0)\n",
    "\n",
    "    # Calculate the average loss for the epoch\n",
    "    average_loss = epoch_loss / num_batches\n",
    "\n",
    "    # Calculate the accuracy for the epoch\n",
    "    accuracy = epoch_correct / num_samples\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "78b65361-b8c7-4a6c-8b54-4a7fdaf3fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(network, loss_fn, dataloader, device=\"cpu\"):\n",
    "    # Set the network to evaluation mode\n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "\n",
    "    # Initialize variables to keep track of loss and number of batches\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    epoch_correct = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    # Turn off gradients\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the data loader\n",
    "        for batch_inputs, batch_targets in dataloader:\n",
    "            # Move data to the appropriate device (e.g., GPU)\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            batch_outputs = network(batch_inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(batch_outputs, batch_targets)\n",
    "\n",
    "            # Accumulate the loss\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            # Calculate the number of correct predictions in the batch\n",
    "            _, predicted = torch.max(batch_outputs, 1)\n",
    "            epoch_correct += (predicted == batch_targets).sum().item()\n",
    "            num_samples += batch_targets.size(0)\n",
    "\n",
    "    # Calculate the average loss for the epoch\n",
    "    average_loss = epoch_loss / num_batches\n",
    "\n",
    "    # Calculate the accuracy for the epoch\n",
    "    accuracy = epoch_correct / num_samples\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bd369170-3ae8-4e00-8cc7-2b2b7dc89b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    network,\n",
    "    loss_fn,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_acc = []\n",
    "    train_acc = []\n",
    "\n",
    "    # Initialize tqdm for progress tracking\n",
    "    progress_bar = tqdm(range(num_epochs), desc=\"Training Progress\")\n",
    "\n",
    "    for epoch in progress_bar:\n",
    "        # Training phase\n",
    "        train_loss, train_accuracy = train_epoch(\n",
    "            network, loss_fn, train_dataloader, optimizer, device=device\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        train_acc.append(train_accuracy)\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_accuracy = validate_epoch(\n",
    "            network, loss_fn, val_dataloader, device=device\n",
    "        )\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc.append(val_accuracy)\n",
    "\n",
    "        # Print the loss for each epoch\n",
    "        # print(\n",
    "        #     f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f},Val Loss: {val_loss:.4f} Val Acc: {accuracy:.4f}\"\n",
    "        # )\n",
    "\n",
    "        # Update tqdm progress bar\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"Train Loss\": train_loss,\n",
    "                \"Val Loss\": val_loss,\n",
    "                \"Train Acc\": train_accuracy,\n",
    "                \"Val Acc\": val_accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e71d7e8f-6447-41b1-af59-a6de31859a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define learning rate\n",
    "# learning_rate = 0.03\n",
    "# batch_size = 128\n",
    "# num_epochs = 100\n",
    "\n",
    "# # Define network\n",
    "# net = Net(hidden_dim=[128, 128], dropout=0.25, activation=nn.ELU())\n",
    "\n",
    "# # Create Adam optimizer\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.5)\n",
    "# # optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# train_losses, val_losses, train_acc, val_acc = train(\n",
    "#     net,\n",
    "#     loss_fn,\n",
    "#     train_dataloader,\n",
    "#     val_dataloader,\n",
    "#     optimizer,\n",
    "#     num_epochs,\n",
    "#     device=\"cpu\",\n",
    "# )\n",
    "\n",
    "# plt.plot(train_losses, label=\"train loss\")\n",
    "# plt.plot(val_losses, label=\"val_loss\")\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(train_acc, label=\"train acc\")\n",
    "# ax.plot(val_acc, label=\"val acc\")\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"epoch\")\n",
    "# ax.set_ylabel(\"accuracy\")\n",
    "# plt.show()\n",
    "\n",
    "# print(\n",
    "#     f\"Best validation accuracy: {max(val_acc) * 100:.2f}% in epoch {val_acc.index(max(val_acc)) + 1}\"\n",
    "# )\n",
    "\n",
    "# # Save the model\n",
    "# torch.save(net.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0667d036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 3\n"
     ]
    }
   ],
   "source": [
    "MATLAB_PATH = \"/Applications/MATLAB_R2024a.app/bin/matlab\"\n",
    "AUDIO_FILE = \"tres_2_3.wav\"\n",
    "\n",
    "# command = f\"{MATLAB_PATH} -batch \\\"extract_features('{AUDIO_FILE}')\\\"\"\n",
    "# subprocess.run(command, shell=True)\n",
    "\n",
    "descriptor = loadmat(\"descriptor.mat\")[\"descriptor\"]\n",
    "descriptor = (descriptor - x_train_mean) / x_train_std\n",
    "\n",
    "testset = TensorDataset(torch.tensor(descriptor, dtype=torch.float32))\n",
    "testloader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "net = Net(hidden_dim=[128, 128], dropout=0.25, activation=nn.ELU())\n",
    "net.load_state_dict(torch.load(\"model.pth\"))\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for num in testloader:\n",
    "        num = num[0]\n",
    "        outputs = net(num)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        prediction = predicted.item()\n",
    "\n",
    "print(f\"Predicted digit: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
